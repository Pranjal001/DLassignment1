{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOdDXt/yrmwbqmcTTzqYCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranjal001/DLassignment1/blob/main/Question_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist , mnist\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "8RQoOMY2um90"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ NEURAL NETWORK ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "class NeuralNet:\n",
        "  def __init__(self, par):\n",
        "\n",
        "#--------------------------------------------defining required paramters within this class--------------------------------------------\n",
        "    self.layer_data = {}\n",
        "\n",
        "    self.hiddenlayers = par['hidden_layers']\n",
        "    self.hiddenlayer_size = par['hidden_layer_size']\n",
        "    self.inputSize = par['input_size']\n",
        "    self.outputSize = par['output_size']\n",
        "    self.activation = par['activation']\n",
        "    self.initialiser = par['initialiser']\n",
        "    self.a = {}\n",
        "    self.h = {}\n",
        "\n",
        "#--------------------------------initialising Layers along with their corresponding Weights and Biases----------------------------------\n",
        "\n",
        "    L = self.hiddenlayers + 1 # 1- input L - hidden 1 - output\n",
        "    self.layer_data[1] = weightsAndBiasLayer(self.inputSize,self.hiddenlayer_size,self.initialiser)\n",
        "\n",
        "    for i in range(2 , L): # 2 , 3,\n",
        "      self.layer_data[i] = weightsAndBiasLayer(self.hiddenlayer_size,self.hiddenlayer_size,self.initialiser)\n",
        "\n",
        "    self.layer_data[L] = weightsAndBiasLayer(self.hiddenlayer_size,self.outputSize,self.initialiser)\n",
        "\n",
        "\n",
        "#-------------------------------------------------Forward Propagate Logic----------------------------------------------------\n",
        "\n",
        "\n",
        "  def forwardpropagate(self,x):\n",
        "\n",
        "    self.h[0] = x\n",
        "    L  = len(self.layer_data)\n",
        "    for i in range(1, L):\n",
        "      self.a[i] = self.layer_data[i].forwarding(self.h[i-1])\n",
        "      self.h[i] = self.layer_data[i].activation_function(self.activation, self.a[i])\n",
        "    self.a[L] = self.layer_data[L].forwarding(self.h[L-1])\n",
        "    y_pred = self.layer_data[L].activation_function('softmax',self.a[L])\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ LAYER CLASS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "class weightsAndBiasLayer:\n",
        "\n",
        "  def __init__(self,lowlayer,upperlayer,initialiser):\n",
        "\n",
        "#-----------------------------------------Defining initialisation method------------------------------------------\n",
        "\n",
        "    if(initialiser == 'random'):\n",
        "      self.weights = np.random.randn(lowlayer,upperlayer)\n",
        "      self.bias = np.random.randn(1,upperlayer)\n",
        "    if(initialiser == 'Xaviar'):\n",
        "      variance = 6.0 / (lowlayer + upperlayer)\n",
        "      stddev = np.sqrt(variance)\n",
        "      self.weights = np.random.randn(lowlayer,upperlayer)*stddev\n",
        "      self.bias = np.random.randn(1,upperlayer)*stddev\n",
        "\n",
        "\n",
        "  def forwarding(self,x):\n",
        "    return np.dot(x,self.weights) + self.bias\n",
        "\n",
        "#----------------------------------------------------Activation functions Definations-------------------------------\n",
        "\n",
        "  def activation_function(self,func_type,x):\n",
        "    if(func_type == 'sigmoid'):\n",
        "      return self.sigmoid(x)\n",
        "    elif(func_type == 'softmax'):\n",
        "      return self.softmax(x)\n",
        "    if(func_type == 'tanh'):\n",
        "      return self.tanh(x)\n",
        "    if(func_type == 'reLu'):\n",
        "      return self.reLu(x)\n",
        "    if(func_type == 'identity'):\n",
        "      return self.identity\n",
        "\n",
        "\n",
        "  def sigmoid(self,input):\n",
        "\n",
        "    return 1.0/(1.0 + np.exp(-input))\n",
        "\n",
        "  def softmax(self,x):\n",
        "    exp_vals = np.exp(x - np.max(x, axis=-1 , keepdims = True))\n",
        "    softmax_vals = exp_vals / np.sum(exp_vals, axis=-1 , keepdims = True)\n",
        "    return softmax_vals\n",
        "\n",
        "  def tanh(self,x):\n",
        "\n",
        "    tan_res =np.tanh(x)\n",
        "    return tan_res\n",
        "\n",
        "  def reLu(self,x):\n",
        "\n",
        "    return np.maximum(0,x)\n",
        "\n",
        "  def identity(self,x):\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "go_wKkL05LGH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  def reshape_1D(data):\n",
        "    return data.reshape(data.shape[0],-1)/255.0\n",
        "\n",
        "  def one_hot_vector(y):\n",
        "    hot_vectors = np.zeros((len(y), 10))  # Initialize array with zeros\n",
        "    hot_vectors[np.arange(len(y)), y] = 1  # Set the corresponding index to 1 for each one-hot vector\n",
        "    return hot_vectors\n",
        "\n",
        "\n",
        "  # ====================================================preprocessing Data=======================================================\n",
        "  (x_train, y_train), (x_test,y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "  # Define class labels\n",
        "  class_labels = {\n",
        "    0: 'T-shirt',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'boot'\n",
        "  }\n",
        "\n",
        "\n",
        "  X_train = reshape_1D(x_train)\n",
        "  Y_train = one_hot_vector(y_train)\n",
        "  X_test = reshape_1D(x_test)\n",
        "  Y_test = one_hot_vector(y_test)\n",
        "\n",
        "\n",
        "  # ====================================================Establishing parametes=======================================================\n",
        "\n",
        "  parameters = {\n",
        "  'epochs' : 32, #number of epochs\n",
        "  'hidden_layers' : 3, #hidden layers neuron count and number of hidden layers\n",
        "  'hidden_layer_size' : 32,\n",
        "  'input_size' : 784,\n",
        "  'output_size' : 10,\n",
        "  'learning_rate' : 0.001, #eta\n",
        "  'beta' : 0.9,  #beta\n",
        "  'beta1' : 0.9,\n",
        "  'beta2' : 0.99,\n",
        "  'epsilon' : 1e-8,\n",
        "  'optimizer' : 'adam', #type of optimizer such as sgd,nadam,nag,\n",
        "  'batch_size' : 16, #16,32\n",
        "  'initialiser' : 'random', #random,xaviar\n",
        "  'activation' : 'sigmoid', #type of actvation\n",
        "  'weight_decay' : 0,\n",
        "  }\n",
        "\n",
        "\n",
        "  # ====================================================Calling feed forward via NeuralNet class=======================================================\n",
        "\n",
        "  Neural_model = NeuralNet(parameters)\n",
        "  predicted = Neural_model.forwardpropagate(X_train[0])\n",
        "  print('Prediction y = ',predicted) #outputing the values of predictions\n",
        "  print('Predictioin Class = ',class_labels[np.argmax(predicted,axis=1)[0]]) #printing prediction index\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P0QXr3Z6WrP",
        "outputId": "d3a0a535-8bca-474f-be7e-c1eda4e15d4d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction y =  [[1.98870757e-03 1.71982676e-03 8.85075219e-05 9.66143501e-01\n",
            "  1.93111867e-02 3.19258043e-05 2.03353421e-05 1.43075309e-04\n",
            "  4.16496245e-05 1.05112841e-02]]\n",
            "Predictioin Class =  Dress\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cwsMFpn37JSH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}